{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to store code that I use which probably will not feature into final investigations. The are two reasons for including this : The first is thorough documentation, while the second is that I might want to play with the architectures or models that will be stored here at a later stage, and I want the convenience of having them handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Res-Net model for Fashion-Mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-01 17:19:22.343478: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from auxiliaries.class_struct import ResidualBlock\n",
    "\n",
    "dataset, info = tfds.load('fashion_mnist', as_supervised = True, with_info = True)\n",
    "dataset_test, dataset_train = dataset['test'], dataset['train']\n",
    "batch_size = 128\n",
    "\n",
    "def convert_types(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255\n",
    "    return image, label\n",
    "\n",
    "dataset_train = dataset_train.map(convert_types).shuffle(10000).batch(batch_size)\n",
    "dataset_test = dataset_test.map(convert_types).batch(batch_size)\n",
    "datagen = ImageDataGenerator(rotation_range = 10, horizontal_flip = True, zoom_range = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  3200      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  multiple                 256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     multiple                  0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  multiple                 0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 75904     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 71552     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 71552     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          multiple                  131584    \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_4 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_5 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_6 (ResidualB  multiple                 282368    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          multiple                  525312    \n",
      "                                                                 \n",
      " residual_block_7 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_8 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_9 (ResidualB  multiple                 1121792   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_10 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_11 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_12 (Residual  multiple                 1121792   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          multiple                  2099200   \n",
      "                                                                 \n",
      " residual_block_13 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_14 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_15 (Residual  multiple                 4471808   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  multiple                 0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2049000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  10010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,313,218\n",
      "Trainable params: 26,267,778\n",
      "Non-trainable params: 45,440\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class ResNet(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            # conv2_x\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 256),\n",
    "            [\n",
    "                ResidualBlock(256, 256) for _ in range(2)                \n",
    "            ],\n",
    "            # conv3_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(512, 512) for _ in range(4)                \n",
    "            ],\n",
    "            # conv4_x\n",
    "            Conv2D(1024, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(1024, 1024) for _ in range(6)                \n",
    "            ],\n",
    "            # conv5_x\n",
    "            Conv2D(2048, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            [\n",
    "                ResidualBlock(2048, 2048) for _ in range(3)\n",
    "            ],\n",
    "            # last part\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "       \n",
    "    \n",
    "model = ResNet((28, 28, 1), 10)\n",
    "model.build(input_shape = (None, 28, 28, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, label):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(image)\n",
    "        loss = loss_object(label, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, predictions)\n",
    "@tf.function\n",
    "def test_step(image, label):\n",
    "    predictions = model(image)\n",
    "    loss = loss_object(label, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_accuracy(label, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.3098554611206055, Accuracy: 8.31556510925293, Test Loss: 2.3028457164764404, Test Accuracy: 10.0, spent_time: 1.6580024480819702 min\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epoch = 1\n",
    "start_time = time.time()\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for epoch in range(num_epoch):    \n",
    "    for image, label in dataset_train:\n",
    "        for _image, _label in datagen.flow(image, label, batch_size =2):\n",
    "            train_step(_image, _label)\n",
    "            break\n",
    "    for test_image, test_label in dataset_test:\n",
    "        test_step(test_image, test_label)\n",
    "    train_accuracies.append(train_accuracy.result())\n",
    "    test_accuracies.append(test_accuracy.result())    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}, spent_time: {} min'\n",
    "    spent_time = time.time() - start_time\n",
    "    print(template.format(epoch + 1, train_loss.result(), train_accuracy.result() * 100, test_loss.result(), test_accuracy.result() * 100, spent_time / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c8ab7546e320b795d1fbe08fe1c89a9101c2a07ae410afc41da9063016fd439"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('vmc')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
